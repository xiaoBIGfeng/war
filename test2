import math
import torch


def trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):
    """
    Fills the input tensor with values drawn from a truncated normal distribution.
    This version avoids in-place operations to support backpropagation.

    Args:
        tensor (torch.Tensor): The tensor to fill.
        mean (float): The mean of the normal distribution.
        std (float): The standard deviation of the normal distribution.
        a (float): The minimum cutoff value.
        b (float): The maximum cutoff value.
    """
    # Compute the upper and lower bounds in the standard normal space
    def norm_cdf(x):
        return (1.0 + torch.erf(x / math.sqrt(2.0))) / 2.0

    # Cutoff values in standard normal space
    low = norm_cdf(torch.tensor((a - mean) / std))
    high = norm_cdf(torch.tensor((b - mean) / std))

    # Uniform sampling in the [low, high] range
    uniform = torch.empty_like(tensor).uniform_(low, high)

    # Transform to a truncated normal distribution using the inverse CDF (probit function)
    normal_sample = torch.erfinv(2 * uniform - 1) * (math.sqrt(2.0) * std) + mean

    # Clamp to the range [a, b]
    normal_sample = torch.clamp(normal_sample, min=a, max=b)

    # Copy the result into the input tensor
    tensor.data.copy_(normal_sample)
    return tensor
